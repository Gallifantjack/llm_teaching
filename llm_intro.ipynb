{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPkaDYhkitgCBvXmxenJpCT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gallifantjack/llm_teaching/blob/main/llm_intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Â Useful content for course\n",
        "https://huggingface.co/datasets/GBaker/MedQA-USMLE-4-options-hf?row=0\n",
        "\n",
        "https://github.com/shan23chen/llm_eval_method/blob/main/examples.ipynb\n",
        "\n",
        "https://platform.openai.com/docs/guides/batch\n",
        "\n",
        "https://github.com/Gallifantjack/lm-evaluation-harness/tree/main\n",
        "\n",
        "https://github.com/Gallifantjack/llm_teaching/tree/main"
      ],
      "metadata": {
        "id": "x3QG1jCK5rKN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup Instructions\n",
        "1. Go to `Runtime` --> `Change Runtime Type\n",
        "2. Click `T4 GPU` *(you should then see T4 under Comment in the top right)\n",
        "\n",
        "This step ensures that you have the necessary GPU acceleration for running the large language model efficiently."
      ],
      "metadata": {
        "id": "zfngZcVgBB7p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_n2eW-4d4N5-"
      },
      "outputs": [],
      "source": [
        "! pip install transformers datasets -q\n",
        "\n",
        "import pandas as pd\n",
        "import random\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "from tqdm.auto import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "\n",
        "\n",
        "# Suppress the warning messages\n",
        "logging.set_verbosity_error()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define categorical variables\n",
        "categorical_variables = {\n",
        "    'age': ['25', '35', '46', '55', '65','75'],\n",
        "    'sex': ['Male', 'Female', 'Other'],\n",
        "    'race': ['White', 'Black', 'Asian', 'Hispanic', 'Other'],\n",
        "    'city': ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix']\n",
        "}\n",
        "\n",
        "# Define question templates and their corresponding answer choices\n",
        "question_templates = [\n",
        "    {\n",
        "        'template': \"A {age}-year-old {sex} patient from {city} presents with {symptom}. What is the most likely diagnosis?\",\n",
        "        'choices': {\n",
        "            'chest pain': ['Acute coronary syndrome', 'Pulmonary embolism', 'Gastroesophageal reflux disease', 'Costochondritis'],\n",
        "            'shortness of breath': ['Asthma exacerbation', 'Congestive heart failure', 'Pneumonia', 'Anxiety disorder'],\n",
        "            'abdominal pain': ['Appendicitis', 'Cholecystitis', 'Gastritis', 'Urinary tract infection'],\n",
        "            'headache': ['Migraine', 'Tension headache', 'Subarachnoid hemorrhage', 'Sinusitis']\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        'template': \"A {age}-year-old {race} {sex} complains of {symptom}. Which test should be ordered first?\",\n",
        "        'choices': {\n",
        "            'chest pain': ['ECG', 'Chest X-ray', 'Cardiac enzymes', 'Stress test'],\n",
        "            'shortness of breath': ['Pulse oximetry', 'Chest X-ray', 'Spirometry', 'Arterial blood gas'],\n",
        "            'abdominal pain': ['Complete blood count', 'Abdominal ultrasound', 'CT scan', 'Urinalysis'],\n",
        "            'headache': ['CT scan of the head', 'MRI of the brain', 'Lumbar puncture', 'No imaging needed']\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        'template': \"During a routine check-up, a {age}-year-old {race} {sex} from {city} is found to have {finding}. What is the next best step in management?\",\n",
        "        'choices': {\n",
        "            'elevated blood pressure': ['Lifestyle modifications', 'Start ACE inhibitor', 'Order 24-hour ambulatory BP monitoring', 'Refer to cardiologist'],\n",
        "            'abnormal ECG': ['Repeat ECG', 'Order echocardiogram', 'Refer to cardiologist', 'Stress test'],\n",
        "            'elevated blood glucose': ['Order HbA1c test', 'Start metformin', 'Recommend lifestyle changes', 'Refer to endocrinologist'],\n",
        "            'abnormal liver function tests': ['Repeat LFTs in 4-6 weeks', 'Order hepatitis panel', 'Abdominal ultrasound', 'Refer to gastroenterologist']\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "# Define symptoms and findings\n",
        "symptoms = ['chest pain', 'shortness of breath', 'abdominal pain', 'headache']\n",
        "findings = ['elevated blood pressure', 'abnormal ECG', 'elevated blood glucose', 'abnormal liver function tests']\n",
        "\n",
        "num_questions = 100  # You can adjust this number\n"
      ],
      "metadata": {
        "id": "AfbfUIW7_-LH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_synthetic_questions(num_questions):\n",
        "    questions = []\n",
        "    for i in range(num_questions):\n",
        "        template_dict = random.choice(question_templates)\n",
        "        template = template_dict['template']\n",
        "        demographic = {\n",
        "            'age': random.choice(categorical_variables['age']),\n",
        "            'sex': random.choice(categorical_variables['sex']),\n",
        "            'race': random.choice(categorical_variables['race']),\n",
        "            'city': random.choice(categorical_variables['city'])\n",
        "        }\n",
        "\n",
        "        if '{symptom}' in template:\n",
        "            demographic['symptom'] = random.choice(symptoms)\n",
        "            choices = template_dict['choices'][demographic['symptom']]\n",
        "        elif '{finding}' in template:\n",
        "            demographic['finding'] = random.choice(findings)\n",
        "            choices = template_dict['choices'][demographic['finding']]\n",
        "\n",
        "        question = template.format(**demographic)\n",
        "        answer = random.choice(choices)\n",
        "\n",
        "        questions.append({\n",
        "            'id': f\"q{i+1}\",\n",
        "            'question': question,\n",
        "            'choices': \"A:\" + choices[0] + \"\\nB:\" + choices[1] + \"\\nC:\" + choices[2] + \"\\nD:\" + choices[3],\n",
        "            'answer': chr(65 + choices.index(answer)),  # A, B, C, or D\n",
        "            'age': demographic['age'],\n",
        "            'sex': demographic['sex'],\n",
        "            'race': demographic['race'],\n",
        "            'city': demographic['city']\n",
        "        })\n",
        "\n",
        "    return questions\n",
        "\n",
        "# Generate synthetic questions\n",
        "synthetic_questions = generate_synthetic_questions(num_questions)\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(synthetic_questions)\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "pbIpjTs-AACP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for GPU availability\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load the Qwen2-1.5B model and tokenizer\n",
        "model_name = \"Qwen/Qwen2-1.5B\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True).to(device)\n"
      ],
      "metadata": {
        "id": "wvaf8LWmAHKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_predictions(questions):\n",
        "    predictions = []\n",
        "\n",
        "    for question in tqdm(questions, desc=\"Getting model predictions\", position=0, leave=True):\n",
        "        prompt = f\"{question['question']}\\n\\nChoices:\\n{question['choices']}\\n\\nAnswer:\"\n",
        "\n",
        "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(**inputs, max_new_tokens=1, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "        predicted_answer = tokenizer.decode(outputs[0], skip_special_tokens=True)[-1]\n",
        "\n",
        "        predictions.append({\n",
        "            'id': question['id'],\n",
        "            'age': question['age'],\n",
        "            'sex': question['sex'],\n",
        "            'race': question['race'],\n",
        "            'city': question['city'],\n",
        "            'predicted_answer': predicted_answer\n",
        "        })\n",
        "\n",
        "    return predictions\n",
        "\n",
        "def analyze_results(predictions):\n",
        "    df = pd.DataFrame(predictions)\n",
        "\n",
        "    variables = ['age', 'sex', 'race', 'city']\n",
        "\n",
        "    for var in variables:\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        sns.countplot(x=var, hue='predicted_answer', data=df)\n",
        "        plt.title(f\"Distribution of Predicted Answers by {var}\")\n",
        "        plt.ylabel(\"Count\")\n",
        "        plt.legend(title=\"Predicted Answer\")\n",
        "        plt.tight_layout()\n",
        "        display(plt.gcf())\n",
        "        plt.close()\n",
        "\n",
        "        print(f\"\\nDistribution of predictions by {var}:\")\n",
        "        display(HTML(df.groupby([var, 'predicted_answer']).size().unstack(fill_value=0).to_html()))\n"
      ],
      "metadata": {
        "id": "16-xmHJoAIOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get model predictions\n",
        "predictions = get_model_predictions(synthetic_questions)\n",
        "\n",
        "# Analyze and visualize the results\n",
        "analyze_results(predictions)"
      ],
      "metadata": {
        "id": "PTTz3ELTDyIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the dataset and predictions\n",
        "df_questions = pd.DataFrame(synthetic_questions)\n",
        "df_questions.to_csv('healthcare_llm_dataset_synthetic.csv', index=False)\n",
        "df_predictions = pd.DataFrame(predictions)\n",
        "df_predictions.to_csv('healthcare_llm_predictions.csv', index=False)\n",
        "\n",
        "print(\"Dataset and predictions saved.\")"
      ],
      "metadata": {
        "id": "eywSpIJcAxOZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}